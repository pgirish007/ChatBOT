<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Hey Portal - Voice Assistant</title>
  <style>
    body {
      font-family: sans-serif;
      text-align: center;
      padding-top: 60px;
    }

    #mic {
      width: 60px;
      height: 60px;
      cursor: pointer;
      position: fixed;
      bottom: 30px;
      right: 30px;
      z-index: 1000;
      transition: transform 0.3s ease;
    }

    #mic.listening {
      animation: pulse 1s infinite;
    }

    @keyframes pulse {
      0% { transform: scale(1); opacity: 0.7; }
      50% { transform: scale(1.2); opacity: 1; }
      100% { transform: scale(1); opacity: 0.7; }
    }

    #log {
      margin-top: 20px;
      font-family: monospace;
      font-size: 14px;
      color: #333;
    }
  </style>
</head>
<body>
  <h2>Click the mic once, then say "Hey Portal"</h2>
  <img id="mic" src="https://cdn-icons-png.flaticon.com/512/61/61088.png" alt="Mic Icon">
  <div id="log"></div>

  <script>
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'en-US';

    const micIcon = document.getElementById("mic");
    const log = document.getElementById("log");

    let isActive = sessionStorage.getItem("mic_active") === "true";
    let transcriptBuffer = "";
    let isSpeaking = false;
    let lastSpokenText = "";
    let lastSpokenTime = 0;

    function logMessage(msg) {
      console.log(msg);
      log.textContent = msg;
    }

    function updateMic(active) {
      micIcon.classList.toggle("listening", active);
      sessionStorage.setItem("mic_active", active);
    }

    function isLikelyEcho(userInput, assistantOutput) {
      if (!userInput || !assistantOutput) return false;

      const now = Date.now();
      const timeSinceSpoken = now - lastSpokenTime;
      if (timeSinceSpoken > 3000) return false;

      const inputWords = userInput.toLowerCase().split(/\s+/);
      const outputWords = assistantOutput.toLowerCase().split(/\s+/);
      const overlap = inputWords.filter(word => outputWords.includes(word)).length;
      const similarity = overlap / Math.max(inputWords.length, outputWords.length);

      return similarity > 0.8;
    }

    function speak(text) {
      const synth = window.speechSynthesis;
      const utter = new SpeechSynthesisUtterance(text);

      utter.onstart = () => {
        isSpeaking = true;
        recognition.abort();
        updateMic(false);
      };

      utter.onend = () => {
        isSpeaking = false;
        lastSpokenText = text;
        lastSpokenTime = Date.now();

        setTimeout(() => {
          if (isActive) {
            recognition.start();
            updateMic(true);
          }
        }, 500);
      };

      synth.speak(utter);
    }

    async function handleCommand(command) {
      const lower = command.toLowerCase();
      let endpoint = "/api/parse-command";

      if (lower.startsWith("search")) {
        endpoint = "/api/search-controller";
      }

      try {
        const response = await fetch(endpoint, {
          method: "POST",
          headers: {
            "Content-Type": "application/json"
          },
          body: JSON.stringify({ command })
        });

        const data = await response.json();
        console.log("API response:", data);

        if (data.action === "redirect" && data.url) {
          speak(`Okay, going to ${data.url}`);
          window.location.href = data.url;
        } else if (data.action === "search" && data.results) {
          speak(`I found ${data.results.length} result${data.results.length !== 1 ? 's' : ''}.`);
          // You can display them here too if you want
        } else {
          speak("You said: " + command);
        }
      } catch (err) {
        console.error("API error:", err);
        speak("Something went wrong processing your request.");
      }
    }

    recognition.onresult = (event) => {
      let interimTranscript = '';
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i];
        const text = result[0].transcript.trim().toLowerCase();
        if (result.isFinal) {
          transcriptBuffer = text;
          logMessage("Heard: " + transcriptBuffer);

          if (!isActive && transcriptBuffer.includes("hey portal")) {
            isActive = true;
            updateMic(true);
            speak("Hi, Iâ€™m listening.");
          } else if (isActive) {
            if (isLikelyEcho(transcriptBuffer, lastSpokenText)) {
              logMessage("Ignored likely echo: " + transcriptBuffer);
              transcriptBuffer = '';
              return;
            }

            if (transcriptBuffer.includes("stop") || transcriptBuffer.includes("goodbye")) {
              isActive = false;
              updateMic(false);
              speak("Okay, talk to you later.");
            } else {
              handleCommand(transcriptBuffer);
            }
          }

          transcriptBuffer = '';
        } else {
          interimTranscript += text;
        }
      }
    };

    recognition.onerror = (event) => {
      logMessage("Error: " + event.error);
      if (event.error === 'not-allowed') {
        alert("Microphone access denied. Please allow it in your browser settings.");
      }
    };

    recognition.onend = () => {
      if (isActive || !isSpeaking) {
        recognition.start();
      }
    };

    micIcon.addEventListener('click', () => {
      recognition.start();
      logMessage("Mic started. Say 'Hey Portal'");
    });

    window.onbeforeunload = () => {
      recognition.stop();
    };

    window.onload = () => {
      if (isActive) {
        recognition.start();
        updateMic(true);
      }
    };
  </script>
</body>
</html>
